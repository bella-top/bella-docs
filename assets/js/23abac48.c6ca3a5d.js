"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[791],{3498:e=>{e.exports=JSON.parse('{"d":[{"id":"bella-openapi","name":"Bella-openapi","description":"\u4e0d\u6b62\u4e8e\u804a\u5929\u8865\u5168\uff0cBella-openapi\u6574\u5408\u4e86\u6587\u672c\u5411\u91cf\u5316\u3001\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u5408\u6210\u3001\u6587\u751f\u56fe\u3001\u56fe\u751f\u56fe\u7b49\u591a\u5143AI\u80fd\u529b\uff0c\u5e76\u914d\u5907\u5b8c\u5584\u7684\u8ba1\u8d39\u3001\u9650\u6d41\u548c\u8d44\u6e90\u7ba1\u7406\u529f\u80fd\u3002\u6240\u6709\u80fd\u529b\u5747\u7ecf\u8fc7\u5927\u89c4\u6a21\u751f\u4ea7\u73af\u5883\u68c0\u9a8c\uff0c\u7a33\u5b9a\u53ef\u9760\u3002","en_description":"Beyond chat completion, Bella-openapi integrates multiple AI capabilities including text vectorization, speech recognition, speech synthesis, text-to-image, and image-to-image generation, equipped with comprehensive billing, rate limiting, and resource management features. All capabilities have been thoroughly tested in large-scale production environments, ensuring stability and reliability.","type":"gateway","status":"released","github":"https://github.com/LianjiaTech/bella-openapi","apiDocPath":"bella-openapi","link":"https://api.bella.top/","documentationLink":"/docs/bella-openapi/intro","dependencies":[{"project":"bella-general-infer","endpoints":"infer-service"}]},{"id":"bella-knowledge","name":"Bella-knowledge","description":"\u4e13\u6ce8\u4e8e\u77e5\u8bc6\u7684\u7edf\u4e00\u5b58\u50a8\u4e0e\u7ba1\u7406\uff0c\u4f18\u96c5\u5904\u7406\u6587\u4ef6\u3001\u95ee\u7b54\u5bf9\u7b49\u591a\u7c7b\u77e5\u8bc6\u6e90\uff0c\u4e3a\u667a\u80fd\u5e94\u7528\u63d0\u4f9b\u5f3a\u5927\u7684\u77e5\u8bc6\u652f\u6491\u3002","en_description":"Focused on unified storage and management of knowledge, elegantly handling multiple knowledge sources such as files and Q&A pairs, providing powerful knowledge support for intelligent applications.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-knowledge","documentationLink":"/docs/bella-knowledge/intro","dependencies":[{"project":"bella-openapi","endpoints":["authorization","billing"]}]},{"id":"bella-assistants","name":"Bella-assistants","description":"\u517c\u5bb9OpenAI Assistants API\u548cResponses API\u7684\u5f00\u6e90\u5b9e\u73b0\uff0c\u7a81\u7834\u539f\u751f\u751f\u6001\u9650\u5236\uff0c\u652f\u6301\u7075\u6d3b\u5207\u6362\u5404\u5927\u5382\u5546\u6a21\u578b\uff0c\u771f\u6b63\u5b9e\u73b0\u4e00\u6b21\u5f00\u53d1\uff0c\u5904\u5904\u53ef\u7528\u3002","en_description":"An open-source implementation compatible with OpenAI Assistants API and Responses API, breaking through native ecosystem limitations, supporting flexible switching between various vendor models, truly achieving develop once, use everywhere.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-assistant","documentationLink":"/docs/bella-assistants/intro","dependencies":[{"project":"bella-openapi","endpoints":["authorization","AI Endpoint"]},{"project":"bella-knowledge","endpoints":["knowledge management"]}]},{"id":"bella-rag","name":"Bella-rag","description":"\u4f9d\u6258Bella-knowledge\u6570\u636e\u6e90\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u68c0\u7d22\u95ee\u7b54\u751f\u6210\u80fd\u529b\uff0c\u652f\u6301\u591a\u79cd\u68c0\u7d22\u65b9\u5f0f\u548cRAG\u5b9e\u73b0\u8303\u5f0f\uff0c\u8ba9AI\u56de\u7b54\u66f4\u7cbe\u51c6\u3001\u66f4\u53ef\u9760\u3002","en_description":"Leveraging Bella-knowledge data sources, it provides unified retrieval question-answering generation capabilities, supports various retrieval methods and RAG implementation paradigms, making AI responses more accurate and reliable.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-rag","documentationLink":"/docs/bella-rag/intro","dependencies":[{"project":"bella-knowledge","endpoints":["knwledge management"]},{"project":"bella-openapi","endpoints":["AI Endpoint"]}]},{"id":"bella-workflow","name":"Bella-workflow","description":"\u7c7b\u4f3cDIFY\u4f46\u62e5\u6709\u8bf8\u591a\u5dee\u5f02\u5316\u80fd\u529b\uff0c\u5982\u56de\u8c03\u6a21\u5f0f\u3001Groovy\u811a\u672c\u652f\u6301\u3001\u6279\u5904\u7406\u80fd\u529b\u3001\u7b2c\u4e09\u65b9\u6570\u636e\u6e90\u6ce8\u518c\u7b49\uff0c\u540c\u65f6\u6027\u80fd\u66f4\u4e3a\u5353\u8d8a\u3002","en_description":"Similar to DIFY but with many differentiated capabilities, such as callback mode, Groovy script support, batch processing capabilities, third-party data source registration, while delivering superior performance.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-workflow","documentationLink":"/docs/bella-workflow/intro","dependencies":[{"project":"bella-openapi","endpoints":["AI Endpoint","authorization","billing"]},{"project":"bella-job-queue","endpoints":["batch"]}]},{"id":"bella-job-queue","name":"Bella-job-queue","description":"\u96c6\u4e2d\u5f0f\u961f\u5217\u7cfb\u7edf\uff0c\u8ba9\u5404\u7c7b\u57fa\u7840\u80fd\u529b\u8f7b\u677e\u652f\u6301\u6279\u5904\u7406\u6a21\u5f0f\uff0c\u5927\u5e45\u63d0\u5347\u5904\u7406\u6548\u7387\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u3002","en_description":"A centralized queue system that enables various basic capabilities to easily support batch processing mode, significantly improving processing efficiency and resource utilization.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-job-queue","documentationLink":"/docs/bella-job-queue/intro"},{"id":"bella-realtime","name":"Bella-realtime","description":"\u4ee5\u8d85\u4f4e\u5ef6\u8fdf\u548c\u6781\u9ad8\u7075\u6d3b\u6027\u8457\u79f0\uff0c\u652f\u6301\u81ea\u7531\u7ec4\u5408\u4e0d\u540c\u7684ASR\u3001LLM\u548cTTS\u7ec4\u4ef6\uff0c\u6253\u9020\u6700\u4f73\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u652f\u6301\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7b49\u524d\u6cbf\u7279\u6027\u3002","en_description":"Known for ultra-low latency and high flexibility, it supports free combination of different ASR, LLM, and TTS components to create the best user experience, while supporting cutting-edge features like multi-agent collaboration.","type":"endpoint","status":"upcoming","github":"https://github.com/LianjiaTech/bella-realtime","documentationLink":"/docs/bella-realtime/intro","dependencies":[{"project":"bella-openapi","endpoints":["TTS","LLM"]},{"project":"bella-whisper","endpoints":["ASR"]}]},{"id":"bella-general-infer","name":"Bella-general-infer","description":"\u652f\u6301LLM\u3001ASR\u3001TTS\u3001Embedding\u3001Rerank\u7b49\u591a\u79cd\u6a21\u578b\uff0c\u517c\u5bb9Transformers\u3001vLLM\u3001SGLang\u3001Faster-Whisper\u7b49\u4e3b\u6d41\u63a8\u7406\u540e\u7aef\uff0c\u4e00\u7ad9\u5f0f\u6ee1\u8db3\u5404\u7c7bAI\u63a8\u7406\u9700\u6c42\u3002","en_description":"Supports multiple models including LLM, ASR, TTS, Embedding, Rerank, compatible with mainstream inference backends such as Transformers, vLLM, SGLang, Faster-Whisper, providing one-stop solution for various AI inference needs.","type":"infer","status":"upcoming","github":"https://github.com/LianjiaTech/bella-general-infer","documentationLink":"/docs/bella-general-infer/intro"},{"id":"bella-whisper","name":"Bella-whisper","description":"\u57fa\u4e8e\u9886\u57df\u6570\u636e\u7cbe\u5fc3\u5fae\u8c03\u7684Whisper\u6a21\u578b\uff0c\u62e5\u6709\u5353\u8d8a\u7684\u7b80\u4f53\u4e2d\u6587\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u8bed\u97f3\u5e94\u7528\u63d0\u4f9b\u66f4\u7cbe\u51c6\u7684\u652f\u6301\u3002","en_description":"A Whisper model carefully fine-tuned with domain data, possessing excellent Simplified Chinese recognition capabilities, providing more accurate support for voice applications.","type":"model","status":"upcoming","github":"https://github.com/LianjiaTech/bella-whisper","documentationLink":"/bella-whisper/intro"}]}')},9485:(e,i,t)=>{t.r(i),t.d(i,{default:()=>m});var n=t(6540),a=t(1410),l=t(539),o=t(6289),s=t(797),r=t(3498);const p={apiViewerContainer:"apiViewerContainer_RsmR",titleContainer:"titleContainer_SNBB",title:"title_pYzp",subtitle:"subtitle_W74e",typeLevels:"typeLevels_EC8m",typeLevel:"typeLevel_dgH5",levelTitleContainer:"levelTitleContainer_xXzA",levelTitle:"levelTitle_x1Hb","levelTitle-gateway":"levelTitle-gateway_ctxU","levelTitle-endpoint":"levelTitle-endpoint_yn1e","levelTitle-infer":"levelTitle-infer_kkyx","levelTitle-model":"levelTitle-model_t5T0","levelTitle-application":"levelTitle-application_JsIx",levelProjectsContainer:"levelProjectsContainer_cBgK",levelProjects:"levelProjects_lLZN",projectCardWrapper:"projectCardWrapper_bOqL",projectCard:"projectCard_sChw",cardContentWrapper:"cardContentWrapper_PpZI","module-gateway":"module-gateway_CQWh","module-endpoint":"module-endpoint_IEJZ","module-infer":"module-infer_TLwX","module-model":"module-model_eJIp","module-application":"module-application_FERO",cardHeader:"cardHeader_Fvu_",cardTitle:"cardTitle_NAsC",statusBadge:"statusBadge_kuB3",released:"released_UmQZ",upcoming:"upcoming_KIAA",cardDescription:"cardDescription_xAs6",cardDescriptionCollapsed:"cardDescriptionCollapsed_JvKG",cardDescriptionExpanded:"cardDescriptionExpanded_z9YR",moreButton:"moreButton_IpXG",viewButton:"viewButton_x3Us",activeButton:"activeButton_PZX4",disabledButton:"disabledButton_GYnM"};var d=t(4848);const c={gateway:{name:"\u7f51\u5173\u5c42",order:1},endpoint:{name:"\u80fd\u529b\u5c42",order:2},infer:{name:"\u63a8\u7406\u670d\u52a1\u5c42",order:3},model:{name:"\u6a21\u578b\u5c42",order:4},application:{name:"\u5e94\u7528\u5c42",order:5}};function u({project:e}){const[i,t]=(0,n.useState)(!1),a=e.description.length>60;return(0,d.jsxs)("div",{className:`${p.projectCard} ${p[`module-${e.type}`]}`,children:[(0,d.jsxs)("div",{className:p.cardHeader,children:[(0,d.jsx)("h3",{className:p.cardTitle,children:e.name}),(0,d.jsx)("span",{className:`${p.statusBadge} ${p[e.status]}`,children:"released"===e.status?"\u5df2\u53d1\u5e03":"\u5373\u5c06\u63a8\u51fa"})]}),(0,d.jsxs)("div",{className:p.cardContentWrapper,children:[(0,d.jsx)("p",{className:`${p.cardDescription} ${i?p.cardDescriptionExpanded:p.cardDescriptionCollapsed}`,children:e.description}),a&&(0,d.jsxs)("button",{className:p.moreButton,onClick:()=>t(!i),type:"button","aria-label":i?"\u6536\u8d77\u8be6\u60c5":"\u67e5\u770b\u66f4\u591a\u8be6\u60c5",children:[i?"\u6536\u8d77":"\u66f4\u591a",(0,d.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 20 20",fill:"currentColor",style:{transform:i?"rotate(180deg)":"rotate(0deg)"},children:(0,d.jsx)("path",{fillRule:"evenodd",d:"M5.293 7.293a1 1 0 011.414 0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 010-1.414z",clipRule:"evenodd"})})]})]}),e.apiDocPath&&"released"===e.status?(0,d.jsx)(o.A,{to:`/api-docs/${e.id}`,className:`${p.viewButton} ${p.activeButton}`,children:"\u67e5\u770b API \u6587\u6863"}):(0,d.jsx)("div",{className:`${p.viewButton} ${p.disabledButton}`,title:"\u5373\u5c06\u63a8\u51fa",children:"\u67e5\u770b API \u6587\u6863"})]})}function m(){const{i18n:e}=(0,s.A)(),i=(e.currentLocale,(0,n.useMemo)((()=>{const e={};return Object.keys(c).forEach((i=>{e[i]=[]})),r.d.forEach((i=>{i.type&&e[i.type]&&e[i.type].push(i)})),Object.keys(e).forEach((i=>{0===e[i].length&&delete e[i]})),e}),[])),t=(0,n.useMemo)((()=>Object.entries(c).sort(((e,i)=>e[1].order-i[1].order)).map((([e])=>e)).filter((e=>i[e]&&i[e].length>0))),[i]);return(0,d.jsx)(a.A,{title:(0,l.T)({id:"pages.apiViewer.title",message:"API \u6587\u6863"}),description:(0,l.T)({id:"pages.apiViewer.description",message:"Bella API \u5b8c\u6574\u6587\u6863"}),children:(0,d.jsxs)("div",{className:p.apiViewerContainer,children:[(0,d.jsx)("div",{className:p.titleContainer,children:(0,d.jsx)("h1",{className:p.title,children:"API \u6587\u6863"})}),(0,d.jsx)("div",{className:p.typeLevels,children:t.map((e=>(0,d.jsxs)("div",{className:p.typeLevel,children:[(0,d.jsx)("div",{className:p.levelTitleContainer,children:(0,d.jsx)("h2",{className:`${p.levelTitle} ${p[`levelTitle-${e}`]}`,children:c[e]?.name||e})}),(0,d.jsx)("div",{className:p.levelProjectsContainer,children:(0,d.jsx)("div",{className:p.levelProjects,children:i[e]?.map((e=>(0,d.jsx)("div",{className:p.projectCardWrapper,children:(0,d.jsx)(u,{project:e})},e.id)))})})]},e)))})]})})}}}]);