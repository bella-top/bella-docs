"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[9201],{8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const r={},t=i.createContext(r);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(t.Provider,{value:n},e.children)}},9513:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"bella-queue/intro","title":"intro","description":"High-Performance AI Task Queue Processing Engine, Supporting Batch API and Task API","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/bella-queue/intro.md","sourceDirName":"bella-queue","slug":"/bella-queue/intro","permalink":"/en/docs/bella-queue/intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentationSidebar","previous":{"title":"\u4ecb\u7ecd\uff08Introduction\uff09","permalink":"/en/docs/bella-workflow/intro"},"next":{"title":"Worker Development Integration Guide","permalink":"/en/docs/bella-queue/api/worker"}}');var r=s(4848),t=s(8453);const l={},o="Bella-Queue",a={},c=[{value:"\ud83d\udd25 Project Overview",id:"-project-overview",level:2},{value:"\u2728 Features",id:"-features",level:2},{value:"\ud83d\udccb Batch API",id:"-batch-api",level:3},{value:"\u26a1 Task API",id:"-task-api",level:3},{value:"\ud83c\udf9b\ufe0f Queue Management",id:"\ufe0f-queue-management",level:3},{value:"\u2728 Core Advantages",id:"-core-advantages",level:2},{value:"\ud83d\udccd Quick Start",id:"-quick-start",level:2},{value:"Usage Methods",id:"usage-methods",level:3},{value:"Quick Deployment",id:"quick-deployment",level:3},{value:"\u2753 Frequently Asked Questions",id:"-frequently-asked-questions",level:2},{value:"Q1: How to choose between Batch API and Task API?",id:"q1-how-to-choose-between-batch-api-and-task-api",level:3},{value:"Q2: What is the maximum concurrency supported by the system?",id:"q2-what-is-the-maximum-concurrency-supported-by-the-system",level:3},{value:"\ud83d\udc68\u200d\ud83d\udcbb Contributing Guide",id:"-contributing-guide",level:2},{value:"\ud83d\udd10 Commercial Use Notice",id:"-commercial-use-notice",level:2},{value:"\ud83d\udcc3 License Agreement",id:"-license-agreement",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)("div",{align:"center",children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"bella-queue",children:"Bella-Queue"})}),(0,r.jsx)("h3",{children:"High-Performance AI Task Queue Processing Engine, Supporting Batch API and Task API"}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/LICENSE",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/License-MIT-blue?style=flat",alt:"License"})}),"\n",(0,r.jsx)(n.a,{href:"https://www.oracle.com/java/",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/Java-8+-orange?style=flat",alt:"Java"})}),"\n",(0,r.jsx)(n.a,{href:"https://spring.io/projects/spring-boot",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/Spring%20Boot-2.3.12-brightgreen?style=flat",alt:"Spring Boot"})})]})]}),"\n",(0,r.jsx)("div",{align:"center",children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/README.md",children:"\u4e2d\u6587"})," | ",(0,r.jsx)(n.strong,{children:"English"})," | ",(0,r.jsx)(n.a,{href:"https://doc.bella.top/en/",children:"Documentation"})]})}),"\n",(0,r.jsx)(n.h2,{id:"-project-overview",children:"\ud83d\udd25 Project Overview"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Bella-Queue"})," is a ",(0,r.jsx)(n.strong,{children:"high-performance task queue processing engine"})," specifically designed for AI application\nscenarios, committed to providing developers with ",(0,r.jsx)(n.strong,{children:"more reliable, efficient, and user-friendly"})," AI task processing\ncapabilities."]}),"\n",(0,r.jsx)(n.p,{children:"The system adopts modern microservice architecture design, building a comprehensive task scheduling system that supports\nboth Batch API and Task API processing modes. It not only provides powerful task lifecycle management capabilities but\nalso supports multiple response modes and intelligent queue strategies, flexibly addressing various business scenarios\nfrom small-scale real-time processing to large-scale batch processing."}),"\n",(0,r.jsx)(n.p,{children:"Whether for online services requiring high-concurrency real-time responses or offline tasks needing large-scale batch\nprocessing, Bella-Queue provides stable and reliable solutions, making AI application development simpler and more\nefficient."}),"\n",(0,r.jsx)(n.h2,{id:"-features",children:"\u2728 Features"}),"\n",(0,r.jsx)(n.h3,{id:"-batch-api",children:"\ud83d\udccb Batch API"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Batch API is designed for large-scale AI task batch processing"}),", suitable for scenarios that need to process large\namounts of data but don't require high real-time performance, such as bulk content generation, model evaluation, data\nanalysis, etc. By packaging multiple requests into batch processing, it can significantly reduce costs and improve\nprocessing efficiency."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Full OpenAI Protocol Compatibility"}),": 100% compatible with OpenAI Batch API standards, seamless migration of\nexisting applications"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Large-Scale Task Processing"}),": Single Batch API supports up to 50,000 tasks, maximum file size 100MB"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Asynchronous Processing"}),": Background processing without blocking user operations, supports 24-hour completion\nwindow configuration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Progress Tracking"}),": Real-time processing progress updates"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Task Cancellation"}),": Supports active cancellation of incomplete batch processing tasks, completed partial results\nremain accessible"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Result Download"}),": Automatically generates output files and error files upon completion, supports download through\nfile-api"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-task-api",children:"\u26a1 Task API"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Task API is designed for single AI task real-time processing"}),", suitable for scenarios requiring quick response and\nreal-time interaction, such as online customer service, real-time dialogue, instant content generation, etc. Supports\nsingle task submission and processing, provides multiple response modes, meeting different real-time business\nrequirements."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple Response Modes"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"callback"}),": Asynchronous callback mode, HTTP callback notification after task completion, suitable for\nlong-running tasks"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"blocking"}),": Synchronous blocking mode, real-time result return, default timeout 300 seconds, suitable for quick\nresponse scenarios"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"streaming"}),": Streaming response mode, supports SSE real-time streaming response, suitable for scenarios requiring\nreal-time feedback"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"\ufe0f-queue-management",children:"\ud83c\udf9b\ufe0f Queue Management"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Intelligent Queue Strategies"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"fifo"}),": First-in-first-out, processes tasks in order of queue entry time, guarantees processing order"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"round_robin"}),": Round-robin scheduling, alternately pulls tasks from multiple queues, evenly distributes task load"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"active_passive"}),": Active-passive mode, prioritizes pulling tasks from primary queue, pulls from backup queue when\nprimary queue is empty"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sequential"}),": Global sequential execution, ensures each queue can only have one task running at a time, avoids concurrent competition"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Queue Management Capabilities"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Priority Support"}),": Supports 0-N level queue priorities, smaller values have higher priority (0 for online, 1+\nfor offline)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic Registration"}),": Supports dynamic registration of new queues, flexible expansion of business scenarios"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"-core-advantages",children:"\u2728 Core Advantages"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Capability"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u2615 Java-Friendly"})}),(0,r.jsx)(n.td,{children:"Backend built entirely on Java technology stack, facilitating rapid integration with Java's active ecosystem, fully utilizing existing technical expertise"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\ude80 High-Performance Processing"})}),(0,r.jsx)(n.td,{children:"Efficient queue implementation based on Redis + Lua scripts, supporting ten-thousand-level concurrency"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\udd27 OpenAI Compatible"})}),(0,r.jsx)(n.td,{children:"100% compatible with OpenAI Batch API standards, seamless migration of existing applications"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\udd04 Multiple Response Modes"})}),(0,r.jsx)(n.td,{children:"Task API supports callback, blocking, streaming three response modes, meeting various scenario requirements from quick response to long-running tasks"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83c\udfaf Intelligent Scheduling"})}),(0,r.jsx)(n.td,{children:"Queue supports FIFO, round-robin, active-passive, sequential four scheduling strategies, 0-N level priority queues, intelligent task distribution and load balancing"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"-quick-start",children:"\ud83d\udccd Quick Start"}),"\n",(0,r.jsx)(n.h3,{id:"usage-methods",children:"Usage Methods"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Deployment Method"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\udc33 Docker Deployment"})}),(0,r.jsxs)(n.td,{children:["Recommended for quick deployment using Docker, no complex configuration needed, one-click startup of complete service stack (including MySQL, Redis, API).",(0,r.jsx)("br",{}),"For detailed steps, please refer to ",(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/api/deploy/README_EN.md",children:"Deployment Guide"}),"."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\udcbb Source Code Deployment"})}),(0,r.jsxs)(n.td,{children:["Build and deploy from source code in your own environment, full control over configuration and data.",(0,r.jsx)("br",{}),"Suitable for scenarios requiring custom configuration or secondary development."]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"quick-deployment",children:"Quick Deployment"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Prerequisites"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Docker installed and running"}),"\n",(0,r.jsx)(n.li,{children:"docker-compose installed"}),"\n",(0,r.jsx)(n.li,{children:"At least 4GB available memory"}),"\n",(0,r.jsx)(n.li,{children:"bella-openapi project must be deployed and running properly"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"One-Click Startup"})," (Recommended):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Clone the code\ngit clone https://github.com/LianjiaTech/bella-queue.git\ncd bella-queue/api/deploy/docker\n\n# One-click startup of complete service stack\n./start.sh \\\n  --bella-openapi-host https://your-bella-openapi-service.com \\\n  --bella-openapi-key your_bella_openapi_secret_key\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Notes"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--bella-openapi-host"})," and ",(0,r.jsx)(n.code,{children:"--bella-openapi-key"})," are required parameters"]}),"\n",(0,r.jsx)(n.li,{children:"First startup will automatically build application image"}),"\n",(0,r.jsxs)(n.li,{children:["After successful startup, health check: ",(0,r.jsx)(n.a,{href:"http://localhost:8080/actuator/health",children:"http://localhost:8080/actuator/health"})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["For more detailed deployment guide and parameter configuration, please refer\nto ",(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/api/deploy/README_EN.md",children:"Deployment Guide"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"-frequently-asked-questions",children:"\u2753 Frequently Asked Questions"}),"\n",(0,r.jsx)(n.h3,{id:"q1-how-to-choose-between-batch-api-and-task-api",children:"Q1: How to choose between Batch API and Task API?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"A"}),": Choose based on business scenarios:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch API"}),": Large volume tasks, non-real-time, cost reduction \u2192 Bulk content generation, model evaluation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Task API"}),": Single tasks, real-time response, flexible interaction \u2192 Online customer service, real-time dialogue"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"q2-what-is-the-maximum-concurrency-supported-by-the-system",children:"Q2: What is the maximum concurrency supported by the system?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"A"}),": Supports ten-thousand-level concurrency, specific performance depends on hardware configuration and number of\nWorker nodes."]}),"\n",(0,r.jsx)(n.h2,{id:"-contributing-guide",children:"\ud83d\udc68\u200d\ud83d\udcbb Contributing Guide"}),"\n",(0,r.jsx)(n.p,{children:"We warmly welcome community contributions! Contributors need to agree that project maintainers may adjust the open\nsource license as needed, and that contributed code may be used for commercial purposes."}),"\n",(0,r.jsxs)(n.p,{children:["For detailed contribution guidelines, please refer\nto ",(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/CONTRIBUTING_EN.md",children:"Contributing Guide"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"-commercial-use-notice",children:"\ud83d\udd10 Commercial Use Notice"}),"\n",(0,r.jsx)(n.p,{children:"Bella-Queue adopts MIT license agreement, supporting commercial use:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"License & Support"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83c\udf1f Free Usage"})}),(0,r.jsx)(n.td,{children:"Adopts MIT license agreement, allows free use, modification and distribution, including commercial purposes, as long as original copyright notice and license text are retained."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\ud83d\udd27 Technical Support"})}),(0,r.jsx)(n.td,{children:"Provides complete documentation and sample code, supports enterprise-level deployment. For professional technical support, please contact us for commercial support services."})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"-license-agreement",children:"\ud83d\udcc3 License Agreement"}),"\n",(0,r.jsxs)(n.p,{children:["Bella-Queue is open-sourced under MIT license agreement, allowing commercial use. For detailed terms, please refer\nto ",(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue/blob/develop/LICENSE",children:"LICENSE"})," file."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)("div",{align:"center",children:[(0,r.jsx)(n.p,{children:"\xa9 2025 Bella. All rights reserved."}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/LianjiaTech/bella-queue",children:"Project Repository"})," \xb7 ",(0,r.jsx)(n.a,{href:"https://doc.bella.top/en/",children:"Documentation Center"})]})]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);