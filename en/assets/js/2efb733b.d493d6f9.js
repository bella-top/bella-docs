"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[937],{8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var r=s(6540);const t={},i=r.createContext(t);function l(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),r.createElement(i.Provider,{value:n},e.children)}},9198:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"core/tts","title":"Speech Synthesis Interface Documentation","description":"Table of Contents","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/core/tts.md","sourceDirName":"core","slug":"/core/tts","permalink":"/bella-openapi/en/docs/core/tts","draft":false,"unlisted":false,"editUrl":"https://github.com/LianjiaTech/bella-openapi/tree/main/bella-docs/docs/core/tts.md","tags":[],"version":"current","frontMatter":{},"sidebar":"documentationSidebar","previous":{"title":"Single-sentence Voice Recognition Interface Documentation","permalink":"/bella-openapi/en/docs/core/flash-asr"},"next":{"title":"Bella OpenAPI Real-time Voice Dialogue Interface Documentation","permalink":"/bella-openapi/en/docs/core/realtime"}}');var t=s(4848),i=s(8453);const l={},o="Speech Synthesis Interface Documentation",a={},c=[{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Interface Description",id:"interface-description",level:2},{value:"Request",id:"request",level:2},{value:"HTTP Request",id:"http-request",level:3},{value:"Request Body",id:"request-body",level:3},{value:"Voice Options",id:"voice-options",level:4},{value:"Response Format Options",id:"response-format-options",level:4},{value:"Response",id:"response",level:2},{value:"Error Codes",id:"error-codes",level:2},{value:"Examples",id:"examples",level:2},{value:"Request Examples",id:"request-examples",level:3},{value:"Basic Request",id:"basic-request",level:4},{value:"Streaming Response Request",id:"streaming-response-request",level:4},{value:"High-Quality Speech Request",id:"high-quality-speech-request",level:4},{value:"Streaming Response",id:"streaming-response",level:3},{value:"Implementation Examples",id:"implementation-examples",level:2},{value:"JavaScript Client Example",id:"javascript-client-example",level:3},{value:"Python Client Example",id:"python-client-example",level:3},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"speech-synthesis-interface-documentation",children:"Speech Synthesis Interface Documentation"})}),"\n",(0,t.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#interface-description",children:"Interface Description"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#request",children:"Request"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#http-request",children:"HTTP Request"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#request-body",children:"Request Body"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#response",children:"Response"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#error-codes",children:"Error Codes"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#examples",children:"Examples"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#request-examples",children:"Request Examples"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#streaming-response",children:"Streaming Response"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"interface-description",children:"Interface Description"}),"\n",(0,t.jsx)(n.p,{children:"Generates speech from input text. Supports multiple voices and formats, and offers streaming responses suitable for real-time speech synthesis scenarios."}),"\n",(0,t.jsx)(n.h2,{id:"request",children:"Request"}),"\n",(0,t.jsx)(n.h3,{id:"http-request",children:"HTTP Request"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:"POST /v1/audio/speech\n"})}),"\n",(0,t.jsx)(n.h3,{id:"request-body",children:"Request Body"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Required"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"input"}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"Yes"}),(0,t.jsx)(n.td,{children:"The text to generate speech from. Maximum length is 4096 characters"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"model"}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"Yes"}),(0,t.jsx)(n.td,{children:"The TTS model to use, e.g.: tts-1, tts-1-hd, or gpt-4o-mini-tts"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"voice"}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"Yes"}),(0,t.jsx)(n.td,{children:"The voice to use for speech generation. Supported voices depend on the model"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"response_format"}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"Audio format. Supported formats include mp3, opus, aac, flac, wav, and pcm. Default value depends on the model type"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"speed"}),(0,t.jsx)(n.td,{children:"number"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"The speed of the generated audio. Optional values range from 0.25 to 4.0. Default is 1.0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"stream"}),(0,t.jsx)(n.td,{children:"boolean"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"Whether to enable streaming response. Default is true"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"sample_rate"}),(0,t.jsx)(n.td,{children:"integer"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"Audio sampling rate. Default is automatically selected based on model and format"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"user"}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"A unique identifier representing the end user"})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"voice-options",children:"Voice Options"}),"\n",(0,t.jsx)(n.p,{children:"Here are the available voice options and their characteristics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"alloy"}),": Neutral, balanced voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ash"}),": Young, clear voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ballad"}),": Soft, calm voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"coral"}),": Warm, friendly voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"echo"}),": Deep, powerful voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"fable"}),": Authoritative, confident voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"onyx"}),": Deep, solemn voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"nova"}),": Lively, enthusiastic voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"sage"}),": Calm, steady voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"shimmer"}),": Bright, cheerful voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"verse"}),": Lyrical, expressive voice"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"response-format-options",children:"Response Format Options"}),"\n",(0,t.jsx)(n.p,{children:"Here are the supported audio formats and their characteristics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"mp3"}),": High compression ratio, suitable for network transmission, default option"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"opus"}),": Low latency, suitable for real-time applications"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"aac"}),": High quality, suitable for music"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"flac"}),": Lossless compression, suitable for high-quality requirements"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"wav"}),": Uncompressed, suitable for high-quality requirements"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"pcm"}),": Raw audio data"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"response",children:"Response"}),"\n",(0,t.jsx)(n.p,{children:"The interface returns audio file content."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["When ",(0,t.jsx)(n.code,{children:"stream=false"}),", the complete audio file is returned"]}),"\n",(0,t.jsxs)(n.li,{children:["When ",(0,t.jsx)(n.code,{children:"stream=true"}),", audio data is returned as a stream, allowing clients to play while receiving"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The Content-Type of the response is set according to the ",(0,t.jsx)(n.code,{children:"response_format"})," parameter in the request:"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"response_format"}),(0,t.jsx)(n.th,{children:"Content-Type"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"mp3"}),(0,t.jsx)(n.td,{children:"audio/mpeg"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"opus"}),(0,t.jsx)(n.td,{children:"audio/opus"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"aac"}),(0,t.jsx)(n.td,{children:"audio/aac"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"flac"}),(0,t.jsx)(n.td,{children:"audio/flac"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"wav"}),(0,t.jsx)(n.td,{children:"audio/wav"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"pcm"}),(0,t.jsx)(n.td,{children:"audio/pcm"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"error-codes",children:"Error Codes"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Error Code"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"400"}),(0,t.jsx)(n.td,{children:"Request parameter error, such as text too long or incorrect parameter format"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"401"}),(0,t.jsx)(n.td,{children:"Authentication failed, invalid API key"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"403"}),(0,t.jsx)(n.td,{children:"Insufficient permissions, API key doesn't have permission to access the requested resource"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"404"}),(0,t.jsx)(n.td,{children:"Requested resource doesn't exist, such as the specified model doesn't exist"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"429"}),(0,t.jsx)(n.td,{children:"Too many requests, exceeded rate limit"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"500"}),(0,t.jsx)(n.td,{children:"Internal server error"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"503"}),(0,t.jsx)(n.td,{children:"Service temporarily unavailable"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(n.h3,{id:"request-examples",children:"Request Examples"}),"\n",(0,t.jsx)(n.h4,{id:"basic-request",children:"Basic Request"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "input": "The weather today is really nice, sunny, making people feel happy.",\n  "model": "tts-1",\n  "voice": "alloy",\n  "response_format": "mp3",\n  "speed": 1.0\n}\n'})}),"\n",(0,t.jsx)(n.h4,{id:"streaming-response-request",children:"Streaming Response Request"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "input": "The weather today is really nice, sunny, making people feel happy.",\n  "model": "tts-1",\n  "voice": "nova",\n  "response_format": "mp3",\n  "speed": 1.0,\n  "stream": true\n}\n'})}),"\n",(0,t.jsx)(n.h4,{id:"high-quality-speech-request",children:"High-Quality Speech Request"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "input": "The weather today is really nice, sunny, making people feel happy.",\n  "model": "tts-1-hd",\n  "voice": "shimmer",\n  "response_format": "wav",\n  "speed": 0.9,\n  "sample_rate": 24000\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"streaming-response",children:"Streaming Response"}),"\n",(0,t.jsxs)(n.p,{children:["When ",(0,t.jsx)(n.code,{children:"stream=true"}),", the server returns audio data as a stream. Clients can play while receiving, suitable for real-time speech synthesis scenarios such as online customer service, navigation systems, etc."]}),"\n",(0,t.jsx)(n.p,{children:"Advantages of streaming responses:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Low latency"}),": Users don't need to wait for the entire audio generation to complete; they can immediately hear the beginning"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time experience"}),": Suitable for interactive scenarios requiring immediate feedback"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Resource efficiency"}),": Clients can process audio while receiving, reducing memory usage"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"implementation-examples",children:"Implementation Examples"}),"\n",(0,t.jsx)(n.h3,{id:"javascript-client-example",children:"JavaScript Client Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"async function streamSpeech() {\n  const response = await fetch('https://api.example.com/v1/audio/speech', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': 'Bearer YOUR_API_KEY'\n    },\n    body: JSON.stringify({\n      input: \"The weather today is really nice, sunny, making people feel happy.\",\n      model: \"tts-1\",\n      voice: \"nova\",\n      response_format: \"mp3\",\n      stream: true\n    })\n  });\n\n  if (!response.ok) {\n    throw new Error(`HTTP error! status: ${response.status}`);\n  }\n\n  // Create audio context\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n  const reader = response.body.getReader();\n  \n  // Process audio stream\n  const processStream = async () => {\n    const { done, value } = await reader.read();\n    if (done) return;\n    \n    // Decode and play audio data\n    audioContext.decodeAudioData(value.buffer, (buffer) => {\n      const source = audioContext.createBufferSource();\n      source.buffer = buffer;\n      source.connect(audioContext.destination);\n      source.start(0);\n    });\n    \n    // Continue processing the stream\n    processStream();\n  };\n  \n  processStream();\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"python-client-example",children:"Python Client Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import requests\nimport pyaudio\nimport io\nfrom pydub import AudioSegment\n\ndef stream_speech():\n    url = "https://api.example.com/v1/audio/speech"\n    headers = {\n        "Content-Type": "application/json",\n        "Authorization": "Bearer YOUR_API_KEY"\n    }\n    data = {\n        "input": "The weather today is really nice, sunny, making people feel happy.",\n        "model": "tts-1",\n        "voice": "nova",\n        "response_format": "mp3",\n        "stream": True\n    }\n    \n    # Send request and get streaming response\n    response = requests.post(url, json=data, headers=headers, stream=True)\n    \n    if response.status_code != 200:\n        raise Exception(f"Error: {response.status_code}")\n    \n    # Initialize PyAudio\n    p = pyaudio.PyAudio()\n    stream = p.open(format=pyaudio.paInt16,\n                    channels=1,\n                    rate=24000,\n                    output=True)\n    \n    # Process audio stream\n    buffer = io.BytesIO()\n    for chunk in response.iter_content(chunk_size=4096):\n        if chunk:\n            buffer.write(chunk)\n            # Play when enough data accumulates\n            if buffer.tell() > 8192:\n                buffer.seek(0)\n                audio = AudioSegment.from_mp3(buffer)\n                stream.write(audio.raw_data)\n                buffer = io.BytesIO()\n    \n    # Play remaining data\n    if buffer.tell() > 0:\n        buffer.seek(0)\n        audio = AudioSegment.from_mp3(buffer)\n        stream.write(audio.raw_data)\n    \n    # Close stream\n    stream.stop_stream()\n    stream.close()\n    p.terminate()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Choose appropriate voices"}),": Select suitable voices based on application scenarios; for example, customer service systems can choose warm, friendly voices (coral), while navigation systems can choose clear, authoritative voices (fable)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Control text length"}),": Longer texts may increase generation time; it is recommended to process long texts in segments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Adjust speech speed"}),": Adjust speed according to the application scenario; for example, notifications can be slightly faster, explanations can be slightly slower"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Choose appropriate audio formats"}),": For network transmission, mp3 and opus formats are more compact; for high-quality requirements, wav or flac can be chosen"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Utilize streaming responses"}),": In scenarios requiring real-time feedback, enabling streaming responses can significantly enhance user experience"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);